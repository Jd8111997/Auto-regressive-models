{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport os\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport random\nfrom tqdm import tqdm\nimport shutil\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport zipfile\nimport gzip, pickle\nimport xml.etree.ElementTree as ET \nfrom PIL import Image\nimport tensorflow.compat.v1 as tf\ntf.disable_v2_behavior()\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('../input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with zipfile.ZipFile(\"../input/generative-dog-images/all-dogs.zip\",\"r\") as z:\n    z.extractall(\".\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with zipfile.ZipFile(\"../input/generative-dog-images/Annotation.zip\",\"r\") as z:\n    z.extractall(\".\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls .","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dogs = os.listdir('./all-dogs/')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Total Images =\", len(dogs))\nprint(\"Total breeds=\", len(os.listdir('./Annotation')))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"All_dogs = os.listdir('./all-dogs/')\nAll_breeds = os.listdir('./Annotation/') \n\ncounter = 0; names = []\nTraining_dogs = np.zeros((25000,64,64,3))\n\nfor breed in All_breeds:\n    for dog in os.listdir('./Annotation/'+breed):\n        try: img = Image.open('./all-dogs/'+dog+'.jpg') \n        except: continue           \n        tree = ET.parse('./Annotation/'+breed+'/'+dog)\n        root = tree.getroot()\n        objects = root.findall('object')\n        for o in objects:\n            bndbox = o.find('bndbox') \n            xmin = int(bndbox.find('xmin').text)\n            ymin = int(bndbox.find('ymin').text)\n            xmax = int(bndbox.find('xmax').text)\n            ymax = int(bndbox.find('ymax').text)\n            w = np.min((xmax - xmin, ymax - ymin))\n            img2 = img.crop((xmin, ymin, xmin+w, ymin+w))\n            img2 = img2.resize((64,64), Image.ANTIALIAS)\n            Training_dogs[counter,:,:,:] = np.asarray(img2)\n            names.append(breed)\n            counter += 1\nidx = np.arange(counter)\nnp.random.shuffle(idx)\nTraining_dogs = Training_dogs[idx,:,:,:]\nnames = np.array(names)[idx]\n    \nx = np.random.randint(0,counter,25)\nfor k in range(5):\n    plt.figure(figsize=(15,3))\n    for j in range(5):\n        plt.subplot(1,5,j+1)\n        img = Image.fromarray( Training_dogs[x[k*5+j],:,:,:].astype('uint8') )\n        plt.axis('off')\n        plt.title(names[x[k*5+j]].split('-')[1],fontsize=11)\n        plt.imshow(img)\n    plt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(Training_dogs.shape)\nprint(len(idx))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img=Image.fromarray(Training_dogs[12121,:,:,:].astype('uint8') )\nplt.imshow(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_mask(kernel_size, channels_in, channels_out, input_channels, mask_type, factorized=True):\n    mask = np.zeros(shape=(kernel_size, kernel_size, channels_in, channels_out), dtype=np.float32)\n    mask[:kernel_size//2, :, :, :] = 1\n    mask[kernel_size//2, :kernel_size//2, :, :] = 1\n    \n    if factorized:\n        if mask_type=='B':\n            mask[kernel_size//2, kernel_size//2, :, :] = 1\n    else:\n        w = int(np.ceil(channels_out/input_channels))\n        h = int(np.ceil(channels_in/input_channels))\n        k = mask_type=='A'\n        m0 = np.triu(np.ones(dtype=np.float32, shape=(input_channels,input_channels)), k)\n        m1 = np.repeat(m0, w, axis=1)\n        m2 = np.repeat(m1, h, axis=0)\n        masked_pixel = m2[:channels_in,:channels_out]\n        mask[kernel_size//2, kernel_size//2, :, :] = masked_pixel\n        \n    return mask","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def masked_conv2d(x, channels_out, kernel_size, input_channels, mask_type, factorized):\n    # Get dimensions of the input tensor\n    _, h, w, channels_in = x.shape.as_list()\n    # Create weight and bias variables\n    weights = tf.get_variable('weight', shape=(kernel_size, kernel_size, channels_in, channels_out),  trainable=True)\n    bias = tf.get_variable('bias', shape=(h, w, channels_out), trainable=True)\n    # Create the mask\n    mask = generate_mask(kernel_size, channels_in, channels_out, input_channels=input_channels, mask_type=mask_type, factorized=factorized)\n    # Apply convolution\n    y = tf.nn.conv2d(x, weights*mask, strides=[1, 1, 1, 1], padding='SAME') + bias\n    return y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def residual_block(x_in, channels_out=128, input_channels=None, factorized=True):\n    x = tf.nn.relu(x_in)\n    # Downsample channels using 1x1 convolution\n    with tf.variable_scope('downsample'):\n        x = masked_conv2d(x, channels_out=channels_out, kernel_size=1, input_channels=input_channels, mask_type='B', factorized=factorized)\n    x = tf.nn.relu(x)\n    # Main convolution\n    with tf.variable_scope('conv'):\n        x = masked_conv2d(x, channels_out=channels_out, kernel_size=3, input_channels=input_channels, mask_type='B', factorized=factorized)\n    x = tf.nn.relu(x)\n    # Upsample channels by two using 1x1 convolution\n    with tf.variable_scope('upsample'):\n        x = masked_conv2d(x, channels_out=channels_out*2, kernel_size=1, input_channels=input_channels, mask_type='B', factorized=factorized)\n    return x + x_in","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def pixel_cnn(x, channels_out, factorized):\n    input_channels = x.shape.as_list()[3]\n    inp = tf.cast(x, tf.int32)\n    x = tf.cast(x, tf.float32)\n    with tf.variable_scope('input_conv'):\n        x = masked_conv2d(x, channels_out=128*2, kernel_size=7, input_channels=input_channels, mask_type='A', factorized=factorized)\n    for i in range(12):\n        with tf.variable_scope('res_block_%d' % i):\n            x = residual_block(x, channels_out=128, input_channels=input_channels, factorized=factorized)\n    with tf.variable_scope('output_conv_1'):\n        x = tf.nn.relu(x)\n        x = masked_conv2d(x, channels_out=128, kernel_size=1, input_channels=input_channels, mask_type='B', factorized=factorized)\n    with tf.variable_scope('output_conv_2'):\n        x = tf.nn.relu(x)\n        x = masked_conv2d(x, channels_out=channels_out, kernel_size=1, input_channels=input_channels, mask_type='B', factorized=factorized)\n    \n    x_rshp = tf.reshape(x, [-1, 64, 64, 3, 256])\n    losses = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=inp, logits=x_rshp)\n    loss = tf.reduce_mean(losses) * np.log2(np.e)\n    probs = tf.nn.softmax(x_rshp)\n    return loss, probs, x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_dataset(x, batch_size):\n    dataset = tf.data.Dataset.from_tensor_slices(x)\n    dataset = dataset.repeat()   # Repeat the dataset indefinitely\n    dataset = dataset.shuffle(10000)   # Shuffle the data\n    dataset = dataset.batch(batch_size)  # Create batches of data\n    dataset = dataset.prefetch(batch_size)  # Prefetch data for faster consumption\n    iterator = tf.data.make_initializable_iterator(dataset)  # Create an iterator over the dataset\n    return iterator","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nnrof_epochs = 10\nbatch_size = 32\nfactorized = True\n\ntf.reset_default_graph()\nwith tf.Graph().as_default():\n\n        train_iterator=create_dataset(Training_dogs[:16000, :, :, :], batch_size)\n        eval_sample = tf.placeholder(tf.float32, shape=(None, 64, 64, 3))\n        \n        with tf.variable_scope('model', reuse=False):\n            train_loss, _, _ = pixel_cnn(train_iterator.get_next(), channels_out=3*256, factorized=factorized)\n            \n        with tf.variable_scope('model', reuse=True):\n            eval_sample_loss, eval_sample_probs, _ = pixel_cnn(eval_sample, channels_out=3*256, factorized=factorized)\n            \n    \n        optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n        tvars = tf.trainable_variables()\n        grads, _ = tf.clip_by_global_norm(tf.gradients(train_loss, tvars), 1.0)\n        train_op = optimizer.apply_gradients(zip(grads, tvars))\n\n        sess  = tf.InteractiveSession()\n        sess.run(tf.global_variables_initializer())\n        sess.run(train_iterator.initializer)\n   \n\n        nrof_train_batches = 16000//batch_size\n\n        train_loss_list = []\n        for epoch in range(1, nrof_epochs+1):\n            for i in range(nrof_train_batches):\n                _, loss_ = sess.run([train_op, train_loss])\n                train_loss_list += [ loss_ ]\n                if i % 25 == 0:\n                    print('train epoch: %4d  batch: %4d  loss: %7.3f' % (epoch, i, loss_))\n\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def display_samples(samples):\n      for k in range(4):\n        plt.figure(figsize=(16,4))\n        for j in range(4):\n            plt.subplot(1,4,j+1)\n            img = Image.fromarray( samples[k*4+j,:,:,:].astype('uint8') )\n            plt.axis('off')\n            plt.imshow(img)\n        plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def sample(No_of_samples, noise=None):\n    img = np.zeros((No_of_samples, 64, 64, 3), dtype=np.uint8)\n    img[:, 0, 0, 0] = np.random.choice(256, size=(No_of_samples,))\n    for j in range(64):\n        for k in range(64):\n            for l in range(3):\n                loss, p = sess.run([eval_sample_loss, eval_sample_probs], feed_dict={eval_sample:img})\n                for i in range(No_of_samples):\n                    img[i, j, k, l] = np.random.choice(256, p=p[i, j, k, l])\n    return img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images=sample(16)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure()\ndisplay_samples(images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}